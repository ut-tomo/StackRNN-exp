
======================================================================
Generalization Experiment: Task 9 - Parentheses
======================================================================
Description: Balanced parentheses classification
nchar: 4
Train nmax: 20
Test nmax values: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]
======================================================================

Training on sequences up to length 20...

======================================================================
Starting training: Task 9
======================================================================

  [Curriculum] Epoch 0: nmax = 3
Epoch   0 |  Train loss = 1.0733 | Val loss = 1.4285 | Val acc = 0.7400 | Time: 10.44s | LR: 1.00e-01
  [Curriculum] Epoch 1: nmax = 4
Epoch   1 |  Train loss = 1.0403 | Val loss = 1.3500 | Val acc = 0.6200 | Time: 11.39s | LR: 1.00e-01
  [Curriculum] Epoch 2: nmax = 5
Epoch   2 |  Train loss = 1.0586 | Val loss = 1.2723 | Val acc = 0.4650 | Time: 12.01s | LR: 1.00e-01
  [Curriculum] Epoch 3: nmax = 6
Epoch   3 |  Train loss = 1.0683 | Val loss = 1.2250 | Val acc = 0.3950 | Time: 12.22s | LR: 1.00e-01
  [Curriculum] Epoch 4: nmax = 7
Epoch   4 |  Train loss = 1.1064 | Val loss = 1.2475 | Val acc = 0.5000 | Time: 13.89s | LR: 1.00e-01
  [Curriculum] Epoch 5: nmax = 8
Epoch   5 |  Train loss = 1.1222 | Val loss = 1.2114 | Val acc = 0.5050 | Time: 16.12s | LR: 1.00e-01
  [Curriculum] Epoch 6: nmax = 9
Epoch   6 |  Train loss = 1.1286 | Val loss = 1.1674 | Val acc = 0.3300 | Time: 15.63s | LR: 1.00e-01
  [Curriculum] Epoch 7: nmax = 10
Epoch   7 |  Train loss = 1.1254 | Val loss = 1.1575 | Val acc = 0.2800 | Time: 16.93s | LR: 1.00e-01
  [Curriculum] Epoch 8: nmax = 11
Epoch   8 |  Train loss = 1.1329 | Val loss = 1.1626 | Val acc = 0.2850 | Time: 18.19s | LR: 1.00e-01
  [Curriculum] Epoch 9: nmax = 12
Epoch   9 |  Train loss = 1.1389 | Val loss = 1.1562 | Val acc = 0.3800 | Time: 19.64s | LR: 1.00e-01
  [Curriculum] Epoch 10: nmax = 13
Epoch  10 |  Train loss = 1.1401 | Val loss = 1.1518 | Val acc = 0.2950 | Time: 21.72s | LR: 1.00e-01
  [Curriculum] Epoch 11: nmax = 14
Epoch  11 |  Train loss = 1.1374 | Val loss = 1.1601 | Val acc = 0.2600 | Time: 22.84s | LR: 1.00e-01
  → LR decayed to 5.00e-02
  → Restored best model from epoch 10
  [Curriculum] Epoch 12: nmax = 15
Epoch  12 |  Train loss = 1.1342 | Val loss = 1.1579 | Val acc = 0.2900 | Time: 24.25s | LR: 5.00e-02
  → LR decayed to 2.50e-02
  → Restored best model from epoch 10
  [Curriculum] Epoch 13: nmax = 16
Epoch  13 |  Train loss = 1.1330 | Val loss = 1.1516 | Val acc = 0.2450 | Time: 25.79s | LR: 2.50e-02
  [Curriculum] Epoch 14: nmax = 17
Epoch  14 |  Train loss = 1.1349 | Val loss = 1.1415 | Val acc = 0.2350 | Time: 26.21s | LR: 2.50e-02
Epoch  15 |  Train loss = 1.1311 | Val loss = 1.1418 | Val acc = 0.2650 | Time: 26.86s | LR: 2.50e-02
  → LR decayed to 1.25e-02
  → Restored best model from epoch 14
Epoch  16 |  Train loss = 1.1308 | Val loss = 1.1395 | Val acc = 0.2900 | Time: 27.83s | LR: 1.25e-02
Epoch  17 |  Train loss = 1.1289 | Val loss = 1.1414 | Val acc = 0.2650 | Time: 29.99s | LR: 1.25e-02
  → LR decayed to 6.25e-03
  → Restored best model from epoch 16
Epoch  18 |  Train loss = 1.1284 | Val loss = 1.1404 | Val acc = 0.2600 | Time: 29.80s | LR: 6.25e-03
  → LR decayed to 3.13e-03
  → Restored best model from epoch 16
Epoch  19 |  Train loss = 1.1281 | Val loss = 1.1400 | Val acc = 0.2500 | Time: 31.06s | LR: 3.13e-03
  → LR decayed to 1.56e-03
  → Restored best model from epoch 16
Epoch  20 |  Train loss = 1.1279 | Val loss = 1.1398 | Val acc = 0.2500 | Time: 30.67s | LR: 1.56e-03
  → LR decayed to 7.81e-04
  → Restored best model from epoch 16
Epoch  21 |  Train loss = 1.1278 | Val loss = 1.1397 | Val acc = 0.2500 | Time: 31.91s | LR: 7.81e-04
  → LR decayed to 3.91e-04
  → Restored best model from epoch 16
Epoch  22 |  Train loss = 1.1277 | Val loss = 1.1396 | Val acc = 0.2500 | Time: 31.49s | LR: 3.91e-04
  → LR decayed to 1.95e-04
  → Restored best model from epoch 16
Epoch  23 |  Train loss = 1.1277 | Val loss = 1.1396 | Val acc = 0.2500 | Time: 30.56s | LR: 1.95e-04
  → LR decayed to 9.77e-05
  → Restored best model from epoch 16
Epoch  24 |  Train loss = 1.1277 | Val loss = 1.1396 | Val acc = 0.2500 | Time: 30.40s | LR: 9.77e-05
  → LR decayed to 4.88e-05
  → Restored best model from epoch 16
Epoch  25 |  Train loss = 1.1277 | Val loss = 1.1396 | Val acc = 0.2500 | Time: 31.75s | LR: 4.88e-05
  → LR decayed to 2.44e-05
  → Restored best model from epoch 16
Epoch  26 |  Train loss = 1.1277 | Val loss = 1.1396 | Val acc = 0.2500 | Time: 30.68s | LR: 2.44e-05
  → LR decayed to 1.22e-05
  → Restored best model from epoch 16
Epoch  27 |  Train loss = 1.1277 | Val loss = 1.1396 | Val acc = 0.2500 | Time: 30.58s | LR: 1.22e-05
  → LR decayed to 6.10e-06
  → Restored best model from epoch 16

  → LR < 1e-05, stopping training

Best model saved to ./results/stackrnn_generalization/task9_trainmax20/model_ntask9_nchar4_nhid40_nstack10_seed1.pt
Best Val Loss: 1.1395, Best Val Acc: 0.2900

Training completed!

======================================================================
Training completed
Best validation loss: 1.1395
Best validation accuracy: 0.2900
Final epoch: 27
======================================================================

Evaluating generalization on different sequence lengths...
  Evaluating on nmax=2... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=3... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=4... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=5... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=6... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=7... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=8... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=9... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=10... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=11... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=12... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=13... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=14... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=15... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=16... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=17... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=18... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=19... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=20... Loss: 1.1396, Acc: 0.2500
  Evaluating on nmax=21... Loss: 1.1393, Acc: 0.2400
  Evaluating on nmax=22... Loss: 1.1469, Acc: 0.2550
  Evaluating on nmax=23... Loss: 1.1439, Acc: 0.2400
  Evaluating on nmax=24... Loss: 1.1354, Acc: 0.2500
  Evaluating on nmax=25... Loss: 1.1404, Acc: 0.2800
  Evaluating on nmax=26... Loss: 1.1264, Acc: 0.2650
  Evaluating on nmax=27... Loss: 1.1302, Acc: 0.3100
  Evaluating on nmax=28... Loss: 1.1234, Acc: 0.3250
  Evaluating on nmax=29... Loss: 1.1196, Acc: 0.3350
  Evaluating on nmax=30... Loss: 1.1280, Acc: 0.3650
  Evaluating on nmax=31... Loss: 1.1165, Acc: 0.3250
  Evaluating on nmax=32... Loss: 1.1115, Acc: 0.2800
  Evaluating on nmax=33... Loss: 1.1166, Acc: 0.2900
  Evaluating on nmax=34... Loss: 1.1388, Acc: 0.3350
  Evaluating on nmax=35... Loss: 1.1340, Acc: 0.3250
  Evaluating on nmax=36... Loss: 1.1263, Acc: 0.3000
  Evaluating on nmax=37... Loss: 1.1250, Acc: 0.3150
  Evaluating on nmax=38... Loss: 1.1208, Acc: 0.3150
  Evaluating on nmax=39... Loss: 1.1284, Acc: 0.3500
  Evaluating on nmax=40... Loss: 1.1224, Acc: 0.3250
  Evaluating on nmax=41... Loss: 1.1172, Acc: 0.2950
  Evaluating on nmax=42... Loss: 1.1211, Acc: 0.3400
  Evaluating on nmax=43... Loss: 1.1269, Acc: 0.3250
  Evaluating on nmax=44... Loss: 1.1192, Acc: 0.3200
  Evaluating on nmax=45... Loss: 1.1175, Acc: 0.2950
  Evaluating on nmax=46... Loss: 1.1237, Acc: 0.3000
  Evaluating on nmax=47... Loss: 1.1292, Acc: 0.3150
  Evaluating on nmax=48... Loss: 1.1301, Acc: 0.3100
  Evaluating on nmax=49... Loss: 1.1278, Acc: 0.3150
  Evaluating on nmax=50... Loss: 1.1364, Acc: 0.3100
  Evaluating on nmax=51... Loss: 1.1368, Acc: 0.3150
  Evaluating on nmax=52... Loss: 1.1354, Acc: 0.3050
  Evaluating on nmax=53... Loss: 1.1325, Acc: 0.2750
  Evaluating on nmax=54... Loss: 1.1285, Acc: 0.2700
  Evaluating on nmax=55... Loss: 1.1279, Acc: 0.2850
  Evaluating on nmax=56... Loss: 1.1170, Acc: 0.2600
  Evaluating on nmax=57... Loss: 1.1383, Acc: 0.2850
  Evaluating on nmax=58... Loss: 1.1435, Acc: 0.3050
  Evaluating on nmax=59... Loss: 1.1457, Acc: 0.3400

======================================================================
Generalization Results Summary
======================================================================
nmax       Loss            Accuracy       
----------------------------------------
2          1.1396          0.2500         
3          1.1396          0.2500         
4          1.1396          0.2500         
5          1.1396          0.2500         
6          1.1396          0.2500         
7          1.1396          0.2500         
8          1.1396          0.2500         
9          1.1396          0.2500         
10         1.1396          0.2500         
11         1.1396          0.2500         
12         1.1396          0.2500         
13         1.1396          0.2500         
14         1.1396          0.2500         
15         1.1396          0.2500         
16         1.1396          0.2500         
17         1.1396          0.2500         
18         1.1396          0.2500         
19         1.1396          0.2500         
20         1.1396          0.2500          *
21         1.1393          0.2400         
22         1.1469          0.2550         
23         1.1439          0.2400         
24         1.1354          0.2500         
25         1.1404          0.2800         
26         1.1264          0.2650         
27         1.1302          0.3100         
28         1.1234          0.3250         
29         1.1196          0.3350         
30         1.1280          0.3650         
31         1.1165          0.3250         
32         1.1115          0.2800         
33         1.1166          0.2900         
34         1.1388          0.3350         
35         1.1340          0.3250         
36         1.1263          0.3000         
37         1.1250          0.3150         
38         1.1208          0.3150         
39         1.1284          0.3500         
40         1.1224          0.3250         
41         1.1172          0.2950         
42         1.1211          0.3400         
43         1.1269          0.3250         
44         1.1192          0.3200         
45         1.1175          0.2950         
46         1.1237          0.3000         
47         1.1292          0.3150         
48         1.1301          0.3100         
49         1.1278          0.3150         
50         1.1364          0.3100         
51         1.1368          0.3150         
52         1.1354          0.3050         
53         1.1325          0.2750         
54         1.1285          0.2700         
55         1.1279          0.2850         
56         1.1170          0.2600         
57         1.1383          0.2850         
58         1.1435          0.3050         
59         1.1457          0.3400         
======================================================================
* = training length

Results saved to: ./results/stackrnn_generalization/task9_trainmax20/generalization_results.json
